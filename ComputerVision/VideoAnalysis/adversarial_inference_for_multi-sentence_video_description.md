# [Adversarial Inference for Multi-Sentence Video Description](https://drive.google.com/file/d/1fB6j1GPDbGOuRj9G4tEMq7UwuA93lXvy/view?usp=drivesdk)

## Overview
- apply adversarial techniques during inference 在推理过程中应用对抗性技术
- a multi-discriminator "hybrid" design, where each discriminator
targets one aspect of a description
- Adversarial Inference for video description: 
  - progressively sample sentence candidates for each clip
  - select the best ones based on a discriminator's score
- Hybrid discriminator:
  - one measures the language characteristics of a sentence
  - the second assesses its relevance to a video segment
  - the third measures its coherence with the previous sentence

## Method
- The task of D is to score the descriptions generated by G for a given video. 使用多个Discriminator来对Generator生成的视频描述打分
- Multiple Ds:
  - correct with respect to the video 检查正确性
    - use the mismatched ground truth as well as mismatched generated sentences as our two types of negatives
    - Multimodal Low-rank Bilinear pooling (MLB)
  - fluent within individual sentences 检查单句流畅性 (混乱以及重复的句子被认为是假)
    - DL is given negative inputs with a mixture of randomly shuffled words or with repeated phrases within a sentence.
  - form a coherent story across sentences 检查多句故事的完整性
    - To ensure coherence, we include "shuffled" sentences as negatives 句子次序颠倒的故事被认为是假


## Dataset
- [ActivityNet Captions](http://activity-net.org/download.html)

## Refences
- [Adversarial Inference for Multi-Sentence Video Description (paperswithcode)](https://paperswithcode.com/paper/adversarial-inference-for-multi-sentence)
- [Github adv-inf](https://github.com/jamespark3922/adv-inf)